{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 3202, Spring 2022: Final Coding Project\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "This is your final programming project for CSCI 3202. It is due on Canvas by **11:59 PM on Saturday April 30**.  Your solutions to theoretical questions should be done in Markdown/LateX directly below the associated question. Your solutions to computational questions should include any relevant Python code, as well as results and any written commentary.\n",
    "\n",
    "You have two options for completing your final project for this course. The first option is presented in this notebook and involves implementing a reinforcement learning algorithm and producing a five-minute video that explains your process of solving this problem. The second option is to design your own project that includes the algorithms we've discussed since the midterm - Bayes Nets, Hidden Markov Models, Markov Decision Processes, or Reinforcement Learning - or an algorithm related to one of these that we haven't discussed in class. Your project also needs to include some kind of analysis of how it performed on a specific problem. If you're interested in the design your own project option, you need to discuss your idea with one of the course instructors to get approval. If you do a project without getting approval, you will receive a 0 regardless of the quality of the project. You will also need to produce a short, five-minute video that explains your project.\n",
    "\n",
    "**The rules:**\n",
    "\n",
    "1. Choose EITHER the given problem to submit OR choose your own project topic. \n",
    "\n",
    "2. If you choose your own project topic, please adhere to the following guidelines:\n",
    "- The project needs to be approved by the course instructors.\n",
    "- The project needs to include one of the algorithms we've discussed since the midterm - Bayes Nets, HMMs, MDPs, or Reinforcement Learning - or an algorithm that we haven't discussed in class. \n",
    "- If you do your own project without prior approval, you will receive a 0 for this project.\n",
    "- Your project code, explanation, and results must all be contained in a Jupyter notebook. \n",
    "\n",
    "3. All work, code and analysis must be **your own**.\n",
    "4. You may use your course notes, posted lecture slides, textbook, in-class notebooks and homework solutions as resources.  You may also search online for answers to general knowledge questions, like the form of a probability distribution function, or how to perform a particular operation in Python. You may not use entire segments of code as solutions to any part of this project, e.g. if you find a Python implementation of policy iteration online, you can't use it.\n",
    "5. You may **not** post to message boards or other online resources asking for help.\n",
    "6. **You may not collaborate with classmates or anyone else.**\n",
    "7. This is meant to be like a coding portion of your final exam. So, we will be much less helpful than we typically am with homework. For example, we will not check answers, help debug your code, and so on.\n",
    "8. If you have a question, post it first as a **private** Piazza message. If we decide that it is appropriate for the entire class, then we will make it a public post (and anonymous).\n",
    "9. If something is left open-ended, it is probably because we intend for you to code it up however you want, and only care about the plots/analysis we see at the end. Feel free to ask clarifying questions though.\n",
    "\n",
    "Violation of these rules will result in an **F** and a trip to the Honor Code council.\n",
    "\n",
    "---\n",
    "**By writing your name below, you agree to abide by these rules:**\n",
    "\n",
    "**Your name:** Kyle Moe\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "# added packages\n",
    "import heapq\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "## [100 pts] Problem 1:  Reinforcement learning\n",
    "\n",
    "Consider a **cube** state space defined by $0 \\le x, y, z \\le L$. Suppose you are piloting/programming a drone to learn how to land on a platform at the center of the $z=0$ surface (the bottom). Some assumptions:\n",
    "* In this discrete world, if the drone is at $(x,y,z)$ it means that the box is centered at $(x,y,z)$. There are boxes (states) centered at $(x,y,z)$ for all $0 \\le x,y,z \\le L$. Each state is a 1 unit cube. So when $L=2$ (for example), there are cubes centered at each $x=0,1,2$, $y=0,1,2$ and so on, for a total state space size of $3^3 = 27$ states.\n",
    "* All of the states with $z=0$ are terminal states.\n",
    "* The state at the center of the bottom of the cubic state space is the landing pad. For example, when $L=4$, the landing pad is at $(x,y,z) = (2,2,0)$.\n",
    "* All terminal states ***except*** the landing pad have a reward of -1. The landing pad has a reward of +1.\n",
    "* All non-terminal states have a living reward of -0.01.\n",
    "* The drone takes up exactly 1 cubic unit, and begins in a random non-terminal state.\n",
    "* The available actions in non-terminal states include moving exactly 1 unit Up (+z), Down (-z), North (+y), South (-y), East (+x) or West (-x). In a terminal state, the training episode should end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part A\n",
    "Write a class `MDPLanding` to represent the Markov decision process for this drone. Include methods for:\n",
    "1. `actions(state)`, which should return a list of all actions available from the given state\n",
    "2. `reward(state)`, which should return the reward for the given state\n",
    "3. `result(state, action)`, which should return the resulting state of doing the given action in the given state\n",
    "\n",
    "and attributes for:\n",
    "1. `states`, a list of all the states in the state space, where each state is represented as an $(x,y,z)$ tuple\n",
    "2. `terminal_states`, a dictionary where keys are the terminal state tuples and the values are the rewards associated with those terminal states\n",
    "3. `default_reward`, a scalar for the reward associated with non-terminal states\n",
    "4. `all_actions`, a list of all possible actions (Up, Down, North, South, East, West)\n",
    "5. `discount`, the discount factor (use $\\gamma = 0.999$ for this entire problem)\n",
    "\n",
    "How you feed arguments/information into the class constructor is up to you.\n",
    "\n",
    "Note that actions are *deterministic* here.  The drone does not need to learn transition probabilities for outcomes of particular actions. What the drone does need to learn, however, is where the landing pad is, and how to get there from any initial state.\n",
    "\n",
    "Before moving on to Part B, we recommend that you test that your MDPLanding code is set up correctly. Write unit tests that display the actions for a given state, rewards, results, etc. This will help you identify errors in your implementation and save you a lot of debugging time later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "\n",
    "class MDPLanding:\n",
    "    def __init__(self, L, default_reward=-0.01, gamma=0.999, success_reward=1,failure_reward=-1):\n",
    "        self.L = L\n",
    "        \n",
    "        self.states = []\n",
    "        self.terminal_states = {}\n",
    "        \n",
    "        for i in range(L+1):\n",
    "            for j in range(L+1):\n",
    "                if (i == j) and (i == self.L // 2):\n",
    "                    self.terminal_states[(i,j,0)] = success_reward\n",
    "                else:\n",
    "                    self.terminal_states[(i,j,0)] = failure_reward\n",
    "                for k in range(L+1):\n",
    "                    self.states.append((i,j,k))\n",
    "        \n",
    "        self.default_reward = default_reward\n",
    "        #                  ['up',   'down',  'east',  'west', 'north', 'south']\n",
    "        self.all_actions = [(0,0,1),(0,0,-1),(0,-1,0),(0,1,0),(-1,0,0),(1,0,0)]\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def actions(self, state):\n",
    "        if state not in self.states:\n",
    "            raise ValueError('State provided is not valid')\n",
    "            \n",
    "            \n",
    "        possible_actions = []\n",
    "        for action in self.all_actions:\n",
    "            if tuple(map(sum, zip(action, state))) in self.states:\n",
    "                possible_actions.append(action)\n",
    "        return possible_actions\n",
    "    \n",
    "    def reward(self, state):\n",
    "        if state not in self.states:\n",
    "            raise ValueError('State provided is not valid')\n",
    "            \n",
    "            \n",
    "        if state in self.terminal_states:\n",
    "            return self.terminal_states[state]\n",
    "        return self.default_reward\n",
    "        \n",
    "    def result(self, state, action):\n",
    "        if state not in self.states:\n",
    "            raise ValueError('State provided is not valid')\n",
    "        if action not in self.actions(state):\n",
    "            raise ValueError('Action cannot be made by state')\n",
    "            \n",
    "            \n",
    "        return self.reward(tuple(map(sum, zip(action, state))))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 1), (0, 0, -1), (0, 1, 0), (1, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "mdp = MDPLanding(2)\n",
    "print(mdp.actions((0,0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (1,0,0)\n",
    "b = (0,1,0)\n",
    "c = (0,0,1)\n",
    "tuple(map(sum,zip(a,b,c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Part B\n",
    "Write a function to implement **policy iteration** for this drone landing MDP. Create an MDP environment to represent the $L=4$ case (so 125 total states).\n",
    "\n",
    "Use your function to find an optimal policy for your new MDP environment. Check (by printing to screen) that the policy for the following states are what you expect, and **comment on the results**:\n",
    "1. $(2,2,1)$\n",
    "1. $(0,2,1)$\n",
    "1. $(2,0,1)$\n",
    "\n",
    "The policy for each of these states is the action that the agent should take in that state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "\n",
    "# https://www.baeldung.com/cs/ml-value-iteration-vs-policy-iteration\n",
    "\n",
    "class PI:\n",
    "    def __init__(self, mdp, max_iterations=100):\n",
    "        # initialize value and policy\n",
    "        V = {}\n",
    "        policy = {}\n",
    "        for state in mdp.states:\n",
    "            #if state not in mdp.terminal_states:\n",
    "            V[state] = 0\n",
    "            actions = mdp.actions(state)\n",
    "            policy[state] = actions[np.random.randint(0,len(actions))]\n",
    "\n",
    "\n",
    "        iterations = 0\n",
    "        converged = False\n",
    "        while not converged and iterations < max_iterations:\n",
    "            converged = True\n",
    "            iterations += 1\n",
    "            \n",
    "            # policy evaluation\n",
    "            for state in V:\n",
    "                if state not in mdp.terminal_states:\n",
    "                    V[state] = mdp.result(state, policy[state]) + V[tuple(map(sum, zip(policy[state], state)))]* mdp.gamma\n",
    "\n",
    "            # policy improvement\n",
    "            for state in V:\n",
    "                if state not in mdp.terminal_states:\n",
    "                    old_best = V[state]\n",
    "                    for action in mdp.actions(state):\n",
    "                        action_result = mdp.result(state, action) + V[tuple(map(sum, zip(action, state)))] * mdp.gamma\n",
    "                        if action_result > old_best:\n",
    "                            policy[state] = action\n",
    "                            old_best = action_result\n",
    "                            converged = False\n",
    "        for state in mdp.terminal_states:\n",
    "            V.pop(state)\n",
    "            policy.pop(state)\n",
    "            \n",
    "        print(\"Converged in \" + str(iterations) + \" iterations\")\n",
    "        self.V = V\n",
    "        self.policy = policy\n",
    "        self.mdp = mdp\n",
    "        \n",
    "    def policy_iteration(self, start):\n",
    "        policies = {}\n",
    "        state = start\n",
    "        while state not in self.mdp.terminal_states:\n",
    "            policies[state] = self.policy[state]\n",
    "            state = tuple(map(sum, zip(self.policy[state], state)))\n",
    "        return policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged in 4 iterations\n",
      "Path and policy from (2,2,1): {(2, 2, 1): (-1, 0, 0), (1, 2, 1): (0, -1, 0), (1, 1, 1): (0, 0, -1)}\n",
      "Path and policy from (0,2,1): {(0, 2, 1): (1, 0, 0), (1, 2, 1): (0, -1, 0), (1, 1, 1): (0, 0, -1)}\n",
      "Path and policy from (2,0,1): {(2, 0, 1): (0, 1, 0), (2, 1, 1): (-1, 0, 0), (1, 1, 1): (0, 0, -1)}\n",
      "Path and policy from (2,2,2): {(2, 2, 2): (0, -1, 0), (2, 1, 2): (-1, 0, 0), (1, 1, 2): (0, 0, -1), (1, 1, 1): (0, 0, -1)}\n",
      "Converged in 7 iterations\n",
      "Path and policy from (4,4,4): {(4, 4, 4): (0, -1, 0), (4, 3, 4): (0, -1, 0), (4, 2, 4): (-1, 0, 0), (3, 2, 4): (0, 0, -1), (3, 2, 3): (0, 0, -1), (3, 2, 2): (-1, 0, 0), (2, 2, 2): (0, 0, -1), (2, 2, 1): (0, 0, -1)}\n"
     ]
    }
   ],
   "source": [
    "mdp = MDPLanding(2)\n",
    "pi = PI(mdp)\n",
    "print(\"Path and policy from (2,2,1): \" + str(pi.policy_iteration((2,2,1))))\n",
    "print(\"Path and policy from (0,2,1): \" + str(pi.policy_iteration((0,2,1))))\n",
    "print(\"Path and policy from (2,0,1): \" + str(pi.policy_iteration((2,0,1))))\n",
    "print(\"Path and policy from (2,2,2): \" + str(pi.policy_iteration((2,2,2))))\n",
    "mdp4 = MDPLanding(4)\n",
    "pi4 = PI(mdp4)\n",
    "print(\"Path and policy from (4,4,4): \" + str(pi4.policy_iteration((4,4,4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results demonstraights the ability of this method to converge to the optimal path in few iterations for a small sample space. The paths found have no issue passing by the terminal states with -1 utility to reach the middle and then the optimal finish. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part C\n",
    "\n",
    "Code up a **Q-learning** agent/algorithm to learn how to land the drone. You can do this however you like, as long as you use the MDP class structure defined above.  \n",
    "\n",
    "Your code should include some kind of a wrapper to run many trials to train the agent and learn the Q values.  You also do not need to have a separate function for the actual \"agent\"; your code can just be a \"for\" loop within which you are refining your estimate of the Q values.\n",
    "\n",
    "From each training trial, save the cumulative discounted reward (utility) over the course of that episode. That is, add up all of $\\gamma^t R(s_t)$ where the drone is in state $s_t$ during time step $t$, for the entire sequence. We refer to this as \"cumulative reward\" because we usually refer to \"utility\" as the utility *under an optimal policy*.\n",
    "\n",
    "Some guidelines:\n",
    "* The drone should initialize in a random non-terminal state for each new training episode.\n",
    "* The training episodes should be limited to 50 time steps, even if the drone has not yet landed. If the drone lands (in a terminal state), the training episode is over.\n",
    "* You may use whatever learning rate $\\alpha$ you decide is appropriate, and gives good results.\n",
    "* There are many forms of Q-learning. You can use whatever you would like, subject to the reliability targets in Part D below.\n",
    "* Your code should return:\n",
    "  * The learned Q values associated with each state-action pair.\n",
    "  * The cumulative reward for each training trial. \n",
    "  * Anything else that might be useful in the ensuing analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.\n",
    "\n",
    "class QLearner:\n",
    "    def __init__(self, mdp, episodes=50, gamma=0.999, alpha=0.9, epsilon=0.1):\n",
    "        self.mdp = mdp\n",
    "        self.episodes = episodes\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.starting_states = []\n",
    "        self.cumulativeRewards = []\n",
    "        \n",
    "        self.Q = {}\n",
    "        for state in self.mdp.states:\n",
    "            if state not in self.mdp.terminal_states:\n",
    "                self.starting_states.append(state)\n",
    "            self.Q[state] = {}\n",
    "            for action in self.mdp.actions(state):\n",
    "                self.Q[state][action] = 0\n",
    "        \n",
    "        for episode in range(episodes):\n",
    "            # get starting state from non-terminal states\n",
    "            state = self.starting_states[np.random.randint(len(self.starting_states))]\n",
    "            cumulativeReward = 0\n",
    "            while state not in self.mdp.terminal_states:\n",
    "                # implement epsilon-greedy algorithm to select current action with \n",
    "                # 1-epsilon probability, random otherwise from non-current action\n",
    "\n",
    "                # current action is maximum Q\n",
    "                action = max(self.Q[state], key=self.Q[state].get)\n",
    "                # explore\n",
    "                if (np.random.choice([0, 1], p=[1-epsilon, epsilon])):\n",
    "                    best = -np.Infinity\n",
    "                    a_best = 0\n",
    "                    for a in self.Q[state]:\n",
    "                        if (a != action) and (self.Q[state][a] > best): \n",
    "                            a_best = a\n",
    "                            best = self.Q[state][a]\n",
    "                    action = a_best\n",
    "                    \n",
    "                s_new = tuple(map(sum, zip(action, state)))\n",
    "                r = mdp.reward(s_new)\n",
    "                cumulativeReward += r\n",
    "                \n",
    "                # Update Q\n",
    "                bestNewQ = max(self.Q[s_new], key=self.Q[s_new].get)\n",
    "                self.Q[state][action] += self.alpha * (r + self.gamma * (self.Q[s_new][bestNewQ] - self.Q[state][action]))\n",
    "                state = s_new\n",
    "            self.cumulativeRewards.append(cumulativeReward)\n",
    "        \n",
    "    def QRewards(self):\n",
    "        return self.Q, self.cumulativeRewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q:\n",
      "{(0, 0, 0): {(0, 0, 1): 0, (0, 1, 0): 0, (1, 0, 0): 0}, (0, 0, 1): {(0, 0, 1): -0.009000000000000001, (0, 0, -1): -0.9, (0, 1, 0): -0.009000000000000001, (1, 0, 0): 0.9778723750692464}, (0, 0, 2): {(0, 0, -1): 0.8532108985465542, (0, 1, 0): 0.8710894937734583, (1, 0, 0): -0.018000000000000002}, (0, 1, 0): {(0, 0, 1): 0, (0, -1, 0): 0, (0, 1, 0): 0, (1, 0, 0): 0}, (0, 1, 1): {(0, 0, 1): -0.009000000000000001, (0, 0, -1): -0.9, (0, -1, 0): -0.009000000000000001, (0, 1, 0): -0.009000000000000001, (1, 0, 0): 0.9908882758725389}, (0, 1, 2): {(0, 0, -1): -0.009908100000000001, (0, -1, 0): -0.018000000000000002, (0, 1, 0): -0.0170919, (1, 0, 0): 0.9809703976216692}, (0, 2, 0): {(0, 0, 1): 0, (0, -1, 0): 0, (1, 0, 0): 0}, (0, 2, 1): {(0, 0, 1): -0.018898854806439002, (0, 0, -1): -0.9, (0, -1, 0): 0.9772182067388219, (1, 0, 0): 0.9809707109682151}, (0, 2, 2): {(0, 0, -1): 0.9688733648189618, (0, -1, 0): -0.018000000000000002, (1, 0, 0): -0.018000000000000002}, (1, 0, 0): {(0, 0, 1): 0, (0, 1, 0): 0, (-1, 0, 0): 0, (1, 0, 0): 0}, (1, 0, 1): {(0, 0, 1): -0.009000000000000001, (0, 0, -1): -0.9, (0, 1, 0): 0.9909909793591701, (-1, 0, 0): 0.775095399978703, (1, 0, 0): 0}, (1, 0, 2): {(0, 0, -1): -0.009908100000000001, (0, 1, 0): 0.9809603602008806, (-1, 0, 0): -0.009000000000000001, (1, 0, 0): -0.0170919}, (1, 1, 0): {(0, 0, 1): 0, (0, -1, 0): 0, (0, 1, 0): 0, (-1, 0, 0): 0, (1, 0, 0): 0}, (1, 1, 1): {(0, 0, 1): -0.009000000000000001, (0, 0, -1): 1.0010010010010009, (0, -1, 0): -0.009000000000000001, (0, 1, 0): 0.9790485886954013, (-1, 0, 0): 0, (1, 0, 0): 0}, (1, 1, 2): {(0, 0, -1): 0.9909909909909896, (0, -1, 0): -0.009000000000000001, (0, 1, 0): -0.009000000000000001, (-1, 0, 0): -0.009000000000000001, (1, 0, 0): -0.0170919}, (1, 2, 0): {(0, 0, 1): 0, (0, -1, 0): 0, (-1, 0, 0): 0, (1, 0, 0): 0}, (1, 2, 1): {(0, 0, 1): -0.009000000000000001, (0, 0, -1): -0.9, (0, -1, 0): 0.9909909909908785, (-1, 0, 0): 0.9610672324631353, (1, 0, 0): 0}, (1, 2, 2): {(0, 0, -1): 0.9708929168810838, (0, -1, 0): -0.018000000000000002, (-1, 0, 0): -0.018000000000000002, (1, 0, 0): -0.0260919}, (2, 0, 0): {(0, 0, 1): 0, (0, 1, 0): 0, (-1, 0, 0): 0}, (2, 0, 1): {(0, 0, 1): -0.009000000000000001, (0, 0, -1): -0.9, (0, 1, 0): -0.009000000000000001, (-1, 0, 0): 0.9709835155442859}, (2, 0, 2): {(0, 0, -1): -0.009999727290000001, (0, 1, 0): -0.009908100000000001, (-1, 0, 0): 0.9606265773108511}, (2, 1, 0): {(0, 0, 1): 0, (0, -1, 0): 0, (0, 1, 0): 0, (-1, 0, 0): 0}, (2, 1, 1): {(0, 0, 1): -0.009000000000000001, (0, 0, -1): -0.9, (0, -1, 0): -0.009000000000000001, (0, 1, 0): -0.009000000000000001, (-1, 0, 0): 0.8909999990244198}, (2, 1, 2): {(0, 0, -1): -0.009908100000000001, (0, -1, 0): -0.0170919, (0, 1, 0): -0.025275427290000003, (-1, 0, 0): 0.9709021724954076}, (2, 2, 0): {(0, 0, 1): 0, (0, -1, 0): 0, (-1, 0, 0): 0}, (2, 2, 1): {(0, 0, 1): -0.018000000000000002, (0, 0, -1): -0.9, (0, -1, 0): -0.009908100000000001, (-1, 0, 0): 0.9708089676556737}, (2, 2, 2): {(0, 0, -1): -0.0189081, (0, -1, 0): -0.0189081, (-1, 0, 0): -0.019806954806439}}\n",
      "\n",
      "r:\n",
      "[-1.18, -1.05, -1.02, 1, -1.13, -1.03, -1.07, -1.01, 1, 0.94, 0.98, 1, 0.99, -1.01, 0.95, 0.99, 0.91, 0.94, 0.98, 0.98, 0.99, 0.95, 0.9299999999999999, 1, 0.98, 0.98, 0.98, 0.96, 0.97, 0.95, 0.97, 0.98, 0.97, 0.96, 0.99, 0.99, 0.99, 0.97, 1, 0.98, 0.98, 0.97, 0.9299999999999999, 0.99, 0.99, 0.98, 0.97, 0.97, 0.98, 0.96]\n"
     ]
    }
   ],
   "source": [
    "q, r = QLearner(mdp).QRewards()\n",
    "print(\"q:\\n\" + str(q))\n",
    "print(\"\\nr:\\n\" + str(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part D\n",
    "\n",
    "Initialize the $L=10$ environment (so that the landing pad is at $(5,5,0)$). Run some number of training trials to train the drone.\n",
    "\n",
    "**How do I know if my drone is learned enough?**  If you take the mean cumulative reward across the last 5000 training trials, it should be around 0.80. This means at least about 10,000 (but probably more) training episodes will be necessary. It will take a few seconds on your computer, so start small to test your code.\n",
    "\n",
    "**Then:** Compute block means of cumulative reward from all of your training trials. Use blocks of 500 training trials. This means you need to create some kind of array-like structure such that its first element is the mean of the first 500 trials' cumulative rewards; its second element is the mean of the 501-1000th trials' cumulative rewards; and so on. Make a plot of the block mean rewards as the training progresses. It should increase from about -0.5 initially to somewhere around +0.8.\n",
    "\n",
    "**And:** Print to the screen the mean of the last 5000 trials' cumulative rewards, to verify that it is indeed about 0.80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of last 5000 episodes: 0.8727440000000001\n"
     ]
    }
   ],
   "source": [
    "# Your code here.\n",
    "\n",
    "mdp10 = MDPLanding(10)\n",
    "q, r = QLearner(mdp10, episodes=10000).QRewards()\n",
    "print(\"Mean of last 5000 episodes: \" + str(np.sum(r[5000:])/len(r[5000:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average Cumulative Reward')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "blockMeanRewards = []\n",
    "for i in range(len(r) // 500):\n",
    "    blockMeanRewards.append(np.sum(r[i*500:(i+1)*500]) / len(r[i*500:(i+1)*500]))\n",
    "    \n",
    "plt.plot(np.arange(len(blockMeanRewards)), blockMeanRewards)\n",
    "plt.xlabel(\"Block\")\n",
    "plt.ylabel(\"Average Cumulative Reward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part E\n",
    "\n",
    "**Question 1:** Why does the cumulative reward start off around -0.5 at the beginning of the training?\n",
    "\n",
    "The cumulative average reward begins around -0.5 for the first block of training because of the size of the sample space. We are contending with a 10x10x10 grid meaning 1000 possible states. While only 1/9 of these are starting states, many will still be unexplored after the end of training. Based on the way Q accumulates from previous iterations, we will still be directed to the terminal states for a lot of states where we have too few iterations to have sufficiently explored. However, we will still reach the +1 terminal state often as well as we begin in previously explored states or transition to them throughout an episode.\n",
    "\n",
    "**Question 2:** Why will it be difficult for us to train the drone to reliably obtain rewards much greater than about 0.8?\n",
    "\n",
    "It is difficult to reliably get rewards all that much greater than the limit we can see in the above plot because of the default rewards for passive states. Depending on the starting state, we will have no choice to accumulate at least some of these default rewards at each states. The reduciton from 1 to \\~0.8 is a consequence of the average path the drone has to follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part F\n",
    "Choose three other reward structures, including the terminal rewards and the living rewards, and rerun your policy iteration and Q-learning algorithms with those reward structures. Write a paragraph or two describing the reward structures that you selected, what impact you expected the changes to have on your results, and what changes actually happened. If there was a difference in what you expected and what actually happened, reflect on why there was a difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of last 5000 episodes: 8.6829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average Cumulative Reward')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scale success reward, failure reward, and default reward by 10.\n",
    "\n",
    "mdp10 = MDPLanding(10, success_reward=10,failure_reward=-10, default_reward=-0.1)\n",
    "q, r = QLearner(mdp10, episodes=10000).QRewards()\n",
    "print(\"Mean of last 5000 episodes: \" + str(np.sum(r[5000:])/len(r[5000:])))\n",
    "\n",
    "blockMeanRewards = []\n",
    "for i in range(len(r) // 500):\n",
    "    blockMeanRewards.append(np.sum(r[i*500:(i+1)*500]) / len(r[i*500:(i+1)*500]))\n",
    "    \n",
    "plt.plot(np.arange(len(blockMeanRewards)), blockMeanRewards)\n",
    "plt.xlabel(\"Block\")\n",
    "plt.ylabel(\"Average Cumulative Reward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I expected the above cell to show is that scaling all of the rewards by the same factor should not do anything to change the actual performance except that the cumulative rewards should too be scaled by 10. The algorithm is effectively operating identically as before and may as well have this factor added in after the fact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of last 5000 episodes: 9.869628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average Cumulative Reward')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scale success reward and failure reward but leave default reward unchanged\n",
    "\n",
    "mdp10 = MDPLanding(10, success_reward=10,failure_reward=-10, default_reward=-0.01)\n",
    "q, r = QLearner(mdp10, episodes=10000).QRewards()\n",
    "print(\"Mean of last 5000 episodes: \" + str(np.sum(r[5000:])/len(r[5000:])))\n",
    "\n",
    "blockMeanRewards = []\n",
    "for i in range(len(r) // 500):\n",
    "    blockMeanRewards.append(np.sum(r[i*500:(i+1)*500]) / len(r[i*500:(i+1)*500]))\n",
    "    \n",
    "plt.plot(np.arange(len(blockMeanRewards)), blockMeanRewards)\n",
    "plt.xlabel(\"Block\")\n",
    "plt.ylabel(\"Average Cumulative Reward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Admittedly, the above result caught me off guard. I did not really expect there to be such a drastic increase in the cumulative rewards nor did I think the algorithm would so quickly move past finding mostly negative rewards. What seems to be happening is that the agent feels far more at liberty to explore rather than committing to ending up at a negative terminal state. This is because the loss for each step of exploration and increase in the path length does little to reduce the total reward on account of the accumulated default penalty. Thus, very rapidly, the optimal move at each state tends to get revealed within the large amount of episodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of last 5000 episodes: -0.27406000000000014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Average Cumulative Reward')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase only the default reward\n",
    "\n",
    "mdp10 = MDPLanding(10, success_reward=1,failure_reward=-1, default_reward=-0.1)\n",
    "q, r = QLearner(mdp10, episodes=10000).QRewards()\n",
    "print(\"Mean of last 5000 episodes: \" + str(np.sum(r[5000:])/len(r[5000:])))\n",
    "\n",
    "blockMeanRewards = []\n",
    "for i in range(len(r) // 500):\n",
    "    blockMeanRewards.append(np.sum(r[i*500:(i+1)*500]) / len(r[i*500:(i+1)*500]))\n",
    "    \n",
    "plt.plot(np.arange(len(blockMeanRewards)), blockMeanRewards)\n",
    "plt.xlabel(\"Block\")\n",
    "plt.ylabel(\"Average Cumulative Reward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell is interesting and shows roughly what I expected considering the size of the sample space. By making the default reward -0.1, there is substantial penalty for traversing any state where there is not a positive terminal reward. In a 10x10x10 cube, There are many states (300 ish out of 1000) for which the optimal path requires traversing at least 10 of these regardless so the cumulative reward must, by construction, be negative. It seems that even with the states for which the path is short enough that there is a positive reward, the average is still negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
